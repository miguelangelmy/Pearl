{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8NNfwWXGvn_o"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uLHbYlegKX-",
        "outputId": "2d27380b-7828-415c-9db0-011b87a7ef59"
      },
      "outputs": [],
      "source": [
        "# %pip uninstall Pearl -y\n",
        "# %rm -rf Pearl\n",
        "# !git clone https://github.com/facebookresearch/Pearl.git\n",
        "# %cd Pearl\n",
        "# %pip install .\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Git-projects\\\\Pearl'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('D:\\Git-projects\\Pearl')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing in GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Processing in GPU\")\n",
        "else:\n",
        "    print(\"Processing in CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH6IKdl6wtaR",
        "outputId": "b2a1de80-0574-41a8-bf22-f66d6ec70d42"
      },
      "outputs": [],
      "source": [
        "# %rm -rf pearl_neurips_demo\n",
        "# !git clone https://github.com/PearlAgent/pearl_neurips_demo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vcb70ZC_h3OA",
        "outputId": "93311fab-d80d-45f0-f1bc-52c7feeb58e4"
      },
      "outputs": [],
      "source": [
        "from pearl.neural_networks.sequential_decision_making.q_value_networks import EnsembleQValueNetwork\n",
        "from pearl.replay_buffers.sequential_decision_making.bootstrap_replay_buffer import BootstrapReplayBuffer\n",
        "from pearl.policy_learners.sequential_decision_making.bootstrapped_dqn import BootstrappedDQN\n",
        "from pearl.utils.functional_utils.experimentation.set_seed import set_seed\n",
        "from pearl.action_representation_modules.identity_action_representation_module import IdentityActionRepresentationModule\n",
        "from pearl.history_summarization_modules.lstm_history_summarization_module import LSTMHistorySummarizationModule\n",
        "from pearl.policy_learners.sequential_decision_making.deep_q_learning import DeepQLearning\n",
        "from pearl.replay_buffers.sequential_decision_making.fifo_off_policy_replay_buffer import FIFOOffPolicyReplayBuffer\n",
        "from pearl.utils.functional_utils.train_and_eval.online_learning import online_learning\n",
        "from pearl.pearl_agent import PearlAgent\n",
        "from pearl_neurips_demo.env_model import SequenceClassificationModel\n",
        "from pearl_neurips_demo.env import RecEnv\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing in GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Processing in GPU\")\n",
        "else:\n",
        "    print(\"Processing in CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g1VHtmldi3A2"
      },
      "outputs": [],
      "source": [
        "# load environment\n",
        "# device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SequenceClassificationModel(100).to(device)\n",
        "model.load_state_dict(torch.load(\"pearl_neurips_demo/env_model_state_dict.pt\"))\n",
        "actions = torch.load(\"pearl_neurips_demo/news_embedding_small.pt\")\n",
        "env = RecEnv(list(actions.values())[:100], model)\n",
        "observation, action_space = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kulkpFAvnOQx"
      },
      "outputs": [],
      "source": [
        "# create a pearl agent\n",
        "\n",
        "action_representation_module = IdentityActionRepresentationModule(\n",
        "    max_number_actions=action_space.n,\n",
        "    representation_dim=action_space.action_dim,\n",
        ")\n",
        "\n",
        "# DQN-vanilla\n",
        "agent = PearlAgent(\n",
        "    policy_learner=DeepQLearning(\n",
        "        state_dim=1,\n",
        "        action_space=action_space,\n",
        "        hidden_dims=[64, 64],\n",
        "        training_rounds=1,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
        "    device_id=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jKVfpz9XnQ-i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode 50, step 1000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 100, step 2000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 150, step 3000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 200, step 4000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 250, step 5000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 300, step 6000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 350, step 7000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 400, step 8000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 450, step 9000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 500, step 10000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 550, step 11000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 600, step 12000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 650, step 13000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 700, step 14000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 750, step 15000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 800, step 16000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 850, step 17000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 900, step 18000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 950, step 19000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1000, step 20000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1050, step 21000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1100, step 22000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1150, step 23000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1200, step 24000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1250, step 25000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1300, step 26000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1350, step 27000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1400, step 28000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1450, step 29000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1500, step 30000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1550, step 31000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1600, step 32000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1650, step 33000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1700, step 34000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1750, step 35000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1800, step 36000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1850, step 37000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1900, step 38000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1950, step 39000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2000, step 40000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2050, step 41000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2100, step 42000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2150, step 43000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2200, step 44000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2250, step 45000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2300, step 46000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2350, step 47000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2400, step 48000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2450, step 49000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2500, step 50000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2550, step 51000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2600, step 52000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2650, step 53000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2700, step 54000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2750, step 55000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2800, step 56000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2850, step 57000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2900, step 58000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2950, step 59000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3000, step 60000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3050, step 61000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3100, step 62000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3150, step 63000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3200, step 64000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3250, step 65000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3300, step 66000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3350, step 67000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3400, step 68000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3450, step 69000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3500, step 70000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3550, step 71000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3600, step 72000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3650, step 73000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3700, step 74000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3750, step 75000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3800, step 76000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3850, step 77000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3900, step 78000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3950, step 79000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4000, step 80000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4050, step 81000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4100, step 82000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4150, step 83000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4200, step 84000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4250, step 85000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4300, step 86000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4350, step 87000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4400, step 88000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4450, step 89000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4500, step 90000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4550, step 91000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4600, step 92000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4650, step 93000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4700, step 94000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4750, step 95000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4800, step 96000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4850, step 97000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4900, step 98000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4950, step 99000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 5000, step 100000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# experiment code\n",
        "number_of_steps = 100000\n",
        "record_period = 400\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=1000,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"DQN-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cDauzO74nS4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode 50, step 1000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 100, step 2000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 150, step 3000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 200, step 4000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 250, step 5000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 300, step 6000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 350, step 7000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 400, step 8000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 450, step 9000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 500, step 10000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 550, step 11000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 600, step 12000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 650, step 13000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 700, step 14000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 750, step 15000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 800, step 16000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 850, step 17000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 900, step 18000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 950, step 19000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1000, step 20000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1050, step 21000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1100, step 22000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1150, step 23000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1200, step 24000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1250, step 25000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1300, step 26000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1350, step 27000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1400, step 28000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1450, step 29000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1500, step 30000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1550, step 31000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1600, step 32000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1650, step 33000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1700, step 34000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1750, step 35000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1800, step 36000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1850, step 37000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1900, step 38000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1950, step 39000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2000, step 40000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2050, step 41000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2100, step 42000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2150, step 43000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2200, step 44000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 2250, step 45000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2300, step 46000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2350, step 47000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2400, step 48000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2450, step 49000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2500, step 50000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2550, step 51000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2600, step 52000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2650, step 53000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2700, step 54000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2750, step 55000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2800, step 56000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 2850, step 57000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2900, step 58000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2950, step 59000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3000, step 60000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3050, step 61000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3100, step 62000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3150, step 63000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3200, step 64000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3250, step 65000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3300, step 66000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3350, step 67000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3400, step 68000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 3450, step 69000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3500, step 70000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3550, step 71000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3600, step 72000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3650, step 73000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3700, step 74000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3750, step 75000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3800, step 76000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3850, step 77000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3900, step 78000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3950, step 79000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4000, step 80000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4050, step 81000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4100, step 82000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4150, step 83000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4200, step 84000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4250, step 85000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4300, step 86000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4350, step 87000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4400, step 88000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4450, step 89000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4500, step 90000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4550, step 91000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4600, step 92000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4650, step 93000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4700, step 94000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4750, step 95000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4800, step 96000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 4850, step 97000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4900, step 98000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4950, step 99000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 5000, step 100000, agent=PearlAgent with DeepQLearning, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), FIFOOffPolicyReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Add a LSTM history summarization module\n",
        "\n",
        "agent = PearlAgent(\n",
        "    policy_learner=DeepQLearning(\n",
        "        state_dim=128,\n",
        "        action_space=action_space,\n",
        "        hidden_dims=[64, 64],\n",
        "        training_rounds=5,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    history_summarization_module=LSTMHistorySummarizationModule(\n",
        "        observation_dim=1,\n",
        "        action_dim=100,\n",
        "        hidden_dim=128,\n",
        "        history_length=8,\n",
        "    ),\n",
        "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
        "    device_id=-1,\n",
        ")\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=1000,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"DQN-LSTM-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN-LSTM\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_7Cpzoi3nVAw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode 5, step 100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 10, step 200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 15, step 300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 20, step 400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 25, step 500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 30, step 600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 35, step 700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 40, step 800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 45, step 900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 50, step 1000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 55, step 1100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 60, step 1200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 65, step 1300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 70, step 1400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 75, step 1500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 80, step 1600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 85, step 1700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 90, step 1800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 95, step 1900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 100, step 2000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 105, step 2100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 110, step 2200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 115, step 2300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 120, step 2400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 125, step 2500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 130, step 2600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 135, step 2700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 140, step 2800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 145, step 2900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 150, step 3000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 155, step 3100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 160, step 3200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 165, step 3300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 170, step 3400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 175, step 3500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 180, step 3600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 185, step 3700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 190, step 3800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 195, step 3900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 200, step 4000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 205, step 4100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 210, step 4200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 215, step 4300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 220, step 4400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 225, step 4500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 230, step 4600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 235, step 4700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 240, step 4800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 245, step 4900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 250, step 5000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 255, step 5100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 260, step 5200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 265, step 5300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 270, step 5400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 275, step 5500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 280, step 5600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 285, step 5700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 290, step 5800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 295, step 5900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 300, step 6000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 305, step 6100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 310, step 6200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 315, step 6300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 320, step 6400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 325, step 6500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 330, step 6600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 335, step 6700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 340, step 6800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 345, step 6900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 350, step 7000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 355, step 7100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 360, step 7200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 365, step 7300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 370, step 7400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 375, step 7500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 380, step 7600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 385, step 7700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 390, step 7800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 395, step 7900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 400, step 8000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 405, step 8100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 410, step 8200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 415, step 8300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 420, step 8400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 425, step 8500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 430, step 8600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 435, step 8700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 440, step 8800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 445, step 8900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 450, step 9000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 455, step 9100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 460, step 9200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 465, step 9300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 470, step 9400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 475, step 9500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 480, step 9600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 485, step 9700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 490, step 9800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 495, step 9900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 500, step 10000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 505, step 10100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 510, step 10200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 515, step 10300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 520, step 10400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 525, step 10500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 530, step 10600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 535, step 10700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 540, step 10800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 545, step 10900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 550, step 11000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 555, step 11100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 560, step 11200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 565, step 11300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 570, step 11400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 575, step 11500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 580, step 11600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 585, step 11700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 590, step 11800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 595, step 11900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 600, step 12000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 605, step 12100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 610, step 12200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 615, step 12300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 620, step 12400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 625, step 12500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 630, step 12600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 635, step 12700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 640, step 12800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 645, step 12900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 650, step 13000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 655, step 13100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 660, step 13200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 665, step 13300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 670, step 13400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 675, step 13500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 680, step 13600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 685, step 13700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 690, step 13800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 695, step 13900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 700, step 14000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 705, step 14100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 710, step 14200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 715, step 14300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 720, step 14400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 725, step 14500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 730, step 14600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 735, step 14700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 740, step 14800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 745, step 14900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 750, step 15000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 755, step 15100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 760, step 15200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 765, step 15300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 770, step 15400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 775, step 15500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 780, step 15600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 785, step 15700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 790, step 15800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 795, step 15900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 800, step 16000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 805, step 16100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 810, step 16200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 815, step 16300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 820, step 16400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 825, step 16500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 830, step 16600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 835, step 16700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 840, step 16800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 845, step 16900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 850, step 17000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 855, step 17100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 860, step 17200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 865, step 17300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 870, step 17400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 875, step 17500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 880, step 17600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 885, step 17700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 890, step 17800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 895, step 17900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 8.0\n",
            "episode 900, step 18000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 905, step 18100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 910, step 18200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 915, step 18300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 920, step 18400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 925, step 18500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 930, step 18600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 935, step 18700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 940, step 18800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 945, step 18900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 950, step 19000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 955, step 19100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 960, step 19200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 965, step 19300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 970, step 19400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 975, step 19500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 980, step 19600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 985, step 19700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 990, step 19800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 995, step 19900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1000, step 20000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1005, step 20100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1010, step 20200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1015, step 20300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1020, step 20400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1025, step 20500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1030, step 20600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1035, step 20700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1040, step 20800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1045, step 20900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1050, step 21000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1055, step 21100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1060, step 21200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1065, step 21300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1070, step 21400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1075, step 21500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1080, step 21600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1085, step 21700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1090, step 21800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1095, step 21900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1100, step 22000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1105, step 22100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1110, step 22200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1115, step 22300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1120, step 22400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1125, step 22500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1130, step 22600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1135, step 22700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1140, step 22800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1145, step 22900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1150, step 23000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1155, step 23100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1160, step 23200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1165, step 23300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1170, step 23400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1175, step 23500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1180, step 23600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1185, step 23700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1190, step 23800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1195, step 23900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1200, step 24000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1205, step 24100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1210, step 24200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1215, step 24300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1220, step 24400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1225, step 24500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1230, step 24600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1235, step 24700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1240, step 24800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1245, step 24900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1250, step 25000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1255, step 25100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1260, step 25200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1265, step 25300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1270, step 25400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1275, step 25500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1280, step 25600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1285, step 25700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1290, step 25800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1295, step 25900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1300, step 26000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1305, step 26100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1310, step 26200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1315, step 26300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1320, step 26400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1325, step 26500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1330, step 26600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1335, step 26700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1340, step 26800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1345, step 26900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1350, step 27000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1355, step 27100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1360, step 27200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1365, step 27300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1370, step 27400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1375, step 27500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1380, step 27600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1385, step 27700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1390, step 27800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1395, step 27900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1400, step 28000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1405, step 28100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1410, step 28200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1415, step 28300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1420, step 28400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1425, step 28500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1430, step 28600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1435, step 28700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1440, step 28800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1445, step 28900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1450, step 29000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1455, step 29100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1460, step 29200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1465, step 29300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1470, step 29400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1475, step 29500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1480, step 29600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1485, step 29700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1490, step 29800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1495, step 29900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1500, step 30000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1505, step 30100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1510, step 30200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1515, step 30300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1520, step 30400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1525, step 30500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1530, step 30600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1535, step 30700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1540, step 30800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1545, step 30900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1550, step 31000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1555, step 31100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1560, step 31200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1565, step 31300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1570, step 31400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1575, step 31500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1580, step 31600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1585, step 31700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1590, step 31800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1595, step 31900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1600, step 32000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1605, step 32100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1610, step 32200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1615, step 32300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1620, step 32400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1625, step 32500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1630, step 32600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1635, step 32700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1640, step 32800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1645, step 32900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1650, step 33000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1655, step 33100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1660, step 33200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1665, step 33300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1670, step 33400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1675, step 33500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1680, step 33600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1685, step 33700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1690, step 33800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1695, step 33900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1700, step 34000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1705, step 34100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1710, step 34200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1715, step 34300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1720, step 34400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1725, step 34500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1730, step 34600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1735, step 34700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1740, step 34800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1745, step 34900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1750, step 35000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1755, step 35100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1760, step 35200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1765, step 35300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1770, step 35400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1775, step 35500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1780, step 35600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1785, step 35700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1790, step 35800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1795, step 35900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1800, step 36000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1805, step 36100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1810, step 36200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1815, step 36300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1820, step 36400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1825, step 36500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 7.0\n",
            "episode 1830, step 36600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 1835, step 36700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1840, step 36800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1845, step 36900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1850, step 37000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1855, step 37100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1860, step 37200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1865, step 37300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1870, step 37400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1875, step 37500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1880, step 37600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1885, step 37700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1890, step 37800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1895, step 37900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1900, step 38000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1905, step 38100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1910, step 38200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 1915, step 38300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1920, step 38400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1925, step 38500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 1930, step 38600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1935, step 38700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1940, step 38800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1945, step 38900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1950, step 39000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1955, step 39100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 1960, step 39200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1965, step 39300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 1970, step 39400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 1975, step 39500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1980, step 39600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1985, step 39700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 1990, step 39800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 1995, step 39900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2000, step 40000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2005, step 40100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2010, step 40200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2015, step 40300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2020, step 40400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2025, step 40500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2030, step 40600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2035, step 40700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2040, step 40800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2045, step 40900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2050, step 41000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2055, step 41100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2060, step 41200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2065, step 41300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2070, step 41400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2075, step 41500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2080, step 41600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2085, step 41700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2090, step 41800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2095, step 41900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2100, step 42000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2105, step 42100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2110, step 42200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2115, step 42300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2120, step 42400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2125, step 42500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2130, step 42600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2135, step 42700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2140, step 42800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2145, step 42900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2150, step 43000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2155, step 43100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2160, step 43200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2165, step 43300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2170, step 43400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2175, step 43500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2180, step 43600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2185, step 43700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2190, step 43800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2195, step 43900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2200, step 44000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2205, step 44100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2210, step 44200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2215, step 44300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2220, step 44400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2225, step 44500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2230, step 44600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2235, step 44700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2240, step 44800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 2245, step 44900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2250, step 45000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2255, step 45100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2260, step 45200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2265, step 45300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2270, step 45400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2275, step 45500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2280, step 45600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2285, step 45700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2290, step 45800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2295, step 45900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2300, step 46000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2305, step 46100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2310, step 46200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2315, step 46300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2320, step 46400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2325, step 46500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2330, step 46600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2335, step 46700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2340, step 46800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2345, step 46900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2350, step 47000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2355, step 47100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2360, step 47200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2365, step 47300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2370, step 47400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2375, step 47500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2380, step 47600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2385, step 47700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2390, step 47800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2395, step 47900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2400, step 48000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2405, step 48100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2410, step 48200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2415, step 48300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2420, step 48400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2425, step 48500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2430, step 48600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2435, step 48700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2440, step 48800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2445, step 48900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2450, step 49000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2455, step 49100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 2460, step 49200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2465, step 49300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2470, step 49400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2475, step 49500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2480, step 49600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2485, step 49700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2490, step 49800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2495, step 49900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2500, step 50000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2505, step 50100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2510, step 50200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2515, step 50300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2520, step 50400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2525, step 50500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2530, step 50600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2535, step 50700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2540, step 50800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2545, step 50900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2550, step 51000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2555, step 51100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2560, step 51200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2565, step 51300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2570, step 51400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2575, step 51500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2580, step 51600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2585, step 51700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2590, step 51800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2595, step 51900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2600, step 52000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2605, step 52100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2610, step 52200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2615, step 52300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2620, step 52400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2625, step 52500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2630, step 52600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2635, step 52700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2640, step 52800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2645, step 52900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2650, step 53000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2655, step 53100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2660, step 53200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2665, step 53300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2670, step 53400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2675, step 53500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2680, step 53600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2685, step 53700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2690, step 53800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2695, step 53900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2700, step 54000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2705, step 54100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2710, step 54200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2715, step 54300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2720, step 54400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2725, step 54500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2730, step 54600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2735, step 54700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2740, step 54800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2745, step 54900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2750, step 55000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2755, step 55100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2760, step 55200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2765, step 55300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2770, step 55400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2775, step 55500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2780, step 55600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2785, step 55700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2790, step 55800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2795, step 55900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2800, step 56000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2805, step 56100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 2810, step 56200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2815, step 56300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2820, step 56400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2825, step 56500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2830, step 56600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2835, step 56700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2840, step 56800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2845, step 56900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2850, step 57000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2855, step 57100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2860, step 57200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2865, step 57300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2870, step 57400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 2875, step 57500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2880, step 57600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2885, step 57700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2890, step 57800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 2895, step 57900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2900, step 58000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2905, step 58100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2910, step 58200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2915, step 58300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2920, step 58400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2925, step 58500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 2930, step 58600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2935, step 58700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2940, step 58800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2945, step 58900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2950, step 59000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2955, step 59100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 2960, step 59200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2965, step 59300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2970, step 59400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2975, step 59500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2980, step 59600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2985, step 59700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 2990, step 59800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 2995, step 59900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3000, step 60000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3005, step 60100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3010, step 60200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3015, step 60300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3020, step 60400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3025, step 60500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3030, step 60600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3035, step 60700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3040, step 60800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3045, step 60900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3050, step 61000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3055, step 61100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3060, step 61200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3065, step 61300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3070, step 61400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3075, step 61500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3080, step 61600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3085, step 61700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3090, step 61800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 3095, step 61900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3100, step 62000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3105, step 62100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3110, step 62200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3115, step 62300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3120, step 62400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3125, step 62500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3130, step 62600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3135, step 62700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3140, step 62800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3145, step 62900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3150, step 63000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3155, step 63100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3160, step 63200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3165, step 63300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3170, step 63400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3175, step 63500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3180, step 63600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3185, step 63700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3190, step 63800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3195, step 63900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3200, step 64000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3205, step 64100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3210, step 64200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3215, step 64300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3220, step 64400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3225, step 64500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3230, step 64600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3235, step 64700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3240, step 64800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3245, step 64900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3250, step 65000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3255, step 65100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3260, step 65200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3265, step 65300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3270, step 65400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3275, step 65500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3280, step 65600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3285, step 65700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3290, step 65800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3295, step 65900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3300, step 66000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3305, step 66100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3310, step 66200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3315, step 66300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3320, step 66400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3325, step 66500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3330, step 66600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3335, step 66700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3340, step 66800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3345, step 66900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3350, step 67000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3355, step 67100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3360, step 67200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3365, step 67300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3370, step 67400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3375, step 67500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3380, step 67600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3385, step 67700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3390, step 67800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3395, step 67900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3400, step 68000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3405, step 68100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3410, step 68200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 3415, step 68300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3420, step 68400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3425, step 68500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3430, step 68600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3435, step 68700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3440, step 68800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3445, step 68900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3450, step 69000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3455, step 69100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3460, step 69200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3465, step 69300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3470, step 69400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3475, step 69500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3480, step 69600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3485, step 69700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3490, step 69800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3495, step 69900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3500, step 70000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3505, step 70100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3510, step 70200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3515, step 70300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3520, step 70400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3525, step 70500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3530, step 70600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3535, step 70700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3540, step 70800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3545, step 70900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3550, step 71000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3555, step 71100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3560, step 71200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3565, step 71300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3570, step 71400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3575, step 71500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3580, step 71600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 3585, step 71700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3590, step 71800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3595, step 71900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3600, step 72000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3605, step 72100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3610, step 72200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3615, step 72300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3620, step 72400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3625, step 72500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3630, step 72600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3635, step 72700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3640, step 72800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3645, step 72900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3650, step 73000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3655, step 73100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3660, step 73200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3665, step 73300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3670, step 73400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3675, step 73500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3680, step 73600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3685, step 73700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3690, step 73800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3695, step 73900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3700, step 74000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3705, step 74100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3710, step 74200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3715, step 74300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3720, step 74400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3725, step 74500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3730, step 74600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3735, step 74700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3740, step 74800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3745, step 74900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3750, step 75000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3755, step 75100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3760, step 75200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3765, step 75300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3770, step 75400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3775, step 75500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3780, step 75600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3785, step 75700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3790, step 75800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3795, step 75900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3800, step 76000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3805, step 76100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3810, step 76200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3815, step 76300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3820, step 76400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3825, step 76500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3830, step 76600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3835, step 76700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3840, step 76800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3845, step 76900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3850, step 77000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3855, step 77100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 3860, step 77200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3865, step 77300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3870, step 77400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3875, step 77500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3880, step 77600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 3885, step 77700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3890, step 77800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 3895, step 77900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3900, step 78000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3905, step 78100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3910, step 78200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3915, step 78300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3920, step 78400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3925, step 78500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3930, step 78600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3935, step 78700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3940, step 78800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3945, step 78900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 3950, step 79000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3955, step 79100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3960, step 79200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 3965, step 79300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3970, step 79400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3975, step 79500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3980, step 79600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3985, step 79700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 3990, step 79800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 3995, step 79900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4000, step 80000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4005, step 80100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4010, step 80200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4015, step 80300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4020, step 80400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4025, step 80500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4030, step 80600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4035, step 80700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4040, step 80800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4045, step 80900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4050, step 81000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4055, step 81100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4060, step 81200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4065, step 81300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4070, step 81400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4075, step 81500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4080, step 81600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4085, step 81700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4090, step 81800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4095, step 81900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4100, step 82000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4105, step 82100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4110, step 82200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4115, step 82300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4120, step 82400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4125, step 82500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4130, step 82600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4135, step 82700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4140, step 82800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4145, step 82900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4150, step 83000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4155, step 83100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4160, step 83200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4165, step 83300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4170, step 83400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4175, step 83500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4180, step 83600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4185, step 83700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4190, step 83800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4195, step 83900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4200, step 84000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4205, step 84100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4210, step 84200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4215, step 84300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4220, step 84400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4225, step 84500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4230, step 84600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4235, step 84700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4240, step 84800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4245, step 84900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4250, step 85000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4255, step 85100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4260, step 85200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4265, step 85300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4270, step 85400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4275, step 85500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4280, step 85600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4285, step 85700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4290, step 85800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4295, step 85900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4300, step 86000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4305, step 86100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4310, step 86200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4315, step 86300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4320, step 86400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 4325, step 86500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4330, step 86600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4335, step 86700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4340, step 86800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4345, step 86900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4350, step 87000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4355, step 87100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4360, step 87200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4365, step 87300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4370, step 87400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4375, step 87500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4380, step 87600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4385, step 87700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4390, step 87800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4395, step 87900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4400, step 88000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4405, step 88100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4410, step 88200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4415, step 88300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4420, step 88400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4425, step 88500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4430, step 88600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4435, step 88700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4440, step 88800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4445, step 88900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4450, step 89000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4455, step 89100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4460, step 89200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4465, step 89300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4470, step 89400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4475, step 89500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4480, step 89600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4485, step 89700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4490, step 89800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4495, step 89900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4500, step 90000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4505, step 90100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4510, step 90200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4515, step 90300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4520, step 90400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4525, step 90500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4530, step 90600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4535, step 90700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 6.0\n",
            "episode 4540, step 90800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4545, step 90900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4550, step 91000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4555, step 91100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4560, step 91200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4565, step 91300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4570, step 91400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4575, step 91500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4580, step 91600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4585, step 91700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4590, step 91800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4595, step 91900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4600, step 92000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4605, step 92100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4610, step 92200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4615, step 92300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4620, step 92400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4625, step 92500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4630, step 92600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4635, step 92700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4640, step 92800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4645, step 92900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4650, step 93000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4655, step 93100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4660, step 93200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4665, step 93300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4670, step 93400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4675, step 93500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4680, step 93600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4685, step 93700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4690, step 93800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4695, step 93900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4700, step 94000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 0.0\n",
            "episode 4705, step 94100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4710, step 94200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4715, step 94300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4720, step 94400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4725, step 94500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4730, step 94600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4735, step 94700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4740, step 94800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4745, step 94900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4750, step 95000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4755, step 95100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4760, step 95200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4765, step 95300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4770, step 95400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4775, step 95500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4780, step 95600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4785, step 95700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4790, step 95800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4795, step 95900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4800, step 96000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4805, step 96100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4810, step 96200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4815, step 96300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4820, step 96400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4825, step 96500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4830, step 96600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4835, step 96700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4840, step 96800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4845, step 96900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4850, step 97000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4855, step 97100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4860, step 97200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4865, step 97300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4870, step 97400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4875, step 97500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4880, step 97600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4885, step 97700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4890, step 97800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4895, step 97900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4900, step 98000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4905, step 98100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4910, step 98200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4915, step 98300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4920, step 98400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 2.0\n",
            "episode 4925, step 98500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4930, step 98600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4935, step 98700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 4.0\n",
            "episode 4940, step 98800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4945, step 98900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4950, step 99000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4955, step 99100, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4960, step 99200, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 7.0\n",
            "episode 4965, step 99300, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4970, step 99400, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 5.0\n",
            "episode 4975, step 99500, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4980, step 99600, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 4985, step 99700, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4990, step 99800, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n",
            "episode 4995, step 99900, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 1.0\n",
            "episode 5000, step 100000, agent=PearlAgent with BootstrappedDQN, LSTMHistorySummarizationModule(\n",
            "  (lstm): LSTM(101, 128, num_layers=2, batch_first=True)\n",
            "), BootstrapReplayBuffer, env=<pearl_neurips_demo.env.RecEnv object at 0x00000226BB6C0CA0>\n",
            "return: 3.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Better exploration with BootstrappedDQN-LSTM\n",
        "\n",
        "agent = PearlAgent(\n",
        "    policy_learner=BootstrappedDQN(\n",
        "        q_ensemble_network=EnsembleQValueNetwork(\n",
        "            state_dim=128,\n",
        "            action_dim=100,\n",
        "            ensemble_size=10,\n",
        "            output_dim=1,\n",
        "            hidden_dims=[64, 64],\n",
        "            prior_scale=0.3,\n",
        "        ),\n",
        "        action_space=action_space,\n",
        "        training_rounds=50,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    history_summarization_module=LSTMHistorySummarizationModule(\n",
        "        observation_dim=1,\n",
        "        action_dim=100,\n",
        "        hidden_dim=128,\n",
        "        history_length=8,\n",
        "    ),\n",
        "    replay_buffer=BootstrapReplayBuffer(100_000, 1.0, 10),\n",
        "    device_id=-1,\n",
        ")\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=100,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"BootstrappedDQN-LSTM-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"BootstrappedDQN-LSTM\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
