{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8NNfwWXGvn_o",
        "output": {
          "id": 383783884102102,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "If you haven't installed Pearl, please make sure you install Pearl with the following cell. Otherwise, you can skip the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1uLHbYlegKX-"
      },
      "outputs": [],
      "source": [
        "# %pip uninstall Pearl -y\n",
        "# %rm -rf Pearl\n",
        "# !git clone https://github.com/facebookresearch/Pearl.git\n",
        "# %cd Pearl\n",
        "# %pip install .\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'D:\\\\Git-projects\\\\Pearl'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('D:\\Git-projects\\Pearl')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing in GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Processing in GPU\")\n",
        "else:\n",
        "    print(\"Processing in CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vcb70ZC_h3OA"
      },
      "outputs": [],
      "source": [
        "from pearl.neural_networks.sequential_decision_making.q_value_networks import EnsembleQValueNetwork\n",
        "from pearl.replay_buffers.sequential_decision_making.bootstrap_replay_buffer import BootstrapReplayBuffer\n",
        "from pearl.policy_learners.sequential_decision_making.bootstrapped_dqn import BootstrappedDQN\n",
        "from pearl.utils.functional_utils.experimentation.set_seed import set_seed\n",
        "from pearl.action_representation_modules.identity_action_representation_module import IdentityActionRepresentationModule\n",
        "from pearl.history_summarization_modules.lstm_history_summarization_module import LSTMHistorySummarizationModule\n",
        "from pearl.policy_learners.sequential_decision_making.deep_q_learning import DeepQLearning\n",
        "from pearl.replay_buffers.sequential_decision_making.fifo_off_policy_replay_buffer import FIFOOffPolicyReplayBuffer\n",
        "from pearl.utils.functional_utils.train_and_eval.online_learning import online_learning\n",
        "from pearl.pearl_agent import PearlAgent\n",
        "from pearl.tutorials.single_item_recommender_system_example.env_model import SequenceClassificationModel\n",
        "from pearl.tutorials.single_item_recommender_system_example.env import RecEnv\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Environment\n",
        "This environment's underlying model is trained using the MIND dataset (Wu et al. 2020).\n",
        "\n",
        "Each data point:\n",
        "- A history of impressions clicked by a user\n",
        "- Each impression is represented by an 100-dim vector\n",
        "- A list of impressions and whether or not they are clicked\n",
        "\n",
        "The environment is constructed with the following setup. Note that this example is a contrived example to illustrate Pearl's usage, agent modularity and a subset of features. Not to represent a real-world environment or problem.  \n",
        "- State: a history of impressions by a user (note that we used the history of impressions of instead of clicked impressions to speed up learning in this example. Interested Pearl users can change it to history of clicked impressions with much longer episode length and samples to run the following experiments.)\n",
        "- Dynamic action space: two randomly picked impressions\n",
        "- Action: one of the two impressions\n",
        "- Reward: click\n",
        "- Reset every 20 steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g1VHtmldi3A2",
        "output": {
          "id": 1038395970722928,
          "loadingStatus": "loaded"
        }
      },
      "outputs": [],
      "source": [
        "# load environment\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SequenceClassificationModel(100).to(device)\n",
        "model.load_state_dict(torch.load(\"pearl/tutorials/single_item_recommender_system_example/env_model_state_dict.pt\"))\n",
        "actions = torch.load(\"pearl/tutorials/single_item_recommender_system_example/news_embedding_small.pt\")\n",
        "env = RecEnv(list(actions.values())[:100], model)\n",
        "observation, action_space = env.reset()\n",
        "\n",
        "# experiment code\n",
        "number_of_steps = 100000\n",
        "record_period = 400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vanilla DQN Agent\n",
        "Able to handle dynamic action space but not able to handle partial observability and sparse reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kulkpFAvnOQx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode 5, step 100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 10, step 200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 15, step 300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 20, step 400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 25, step 500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 30, step 600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 35, step 700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 40, step 800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 45, step 900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 50, step 1000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 55, step 1100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 60, step 1200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 65, step 1300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 70, step 1400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 75, step 1500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 80, step 1600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 85, step 1700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 90, step 1800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 95, step 1900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 100, step 2000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 105, step 2100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 110, step 2200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 115, step 2300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 120, step 2400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 125, step 2500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 130, step 2600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 135, step 2700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 140, step 2800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 145, step 2900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 150, step 3000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 155, step 3100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 160, step 3200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 165, step 3300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 170, step 3400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 175, step 3500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 180, step 3600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 185, step 3700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 190, step 3800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 195, step 3900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 200, step 4000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 205, step 4100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 210, step 4200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 215, step 4300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 220, step 4400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 225, step 4500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 230, step 4600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 235, step 4700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 240, step 4800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 245, step 4900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 250, step 5000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 255, step 5100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 260, step 5200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 265, step 5300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 270, step 5400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 275, step 5500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 280, step 5600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 285, step 5700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 290, step 5800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 295, step 5900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 300, step 6000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 305, step 6100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 310, step 6200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 315, step 6300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 320, step 6400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 325, step 6500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 330, step 6600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 335, step 6700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 340, step 6800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 345, step 6900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 350, step 7000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 355, step 7100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 360, step 7200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 365, step 7300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 370, step 7400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 375, step 7500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 380, step 7600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 385, step 7700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 390, step 7800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 395, step 7900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 400, step 8000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 405, step 8100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 410, step 8200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 415, step 8300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 420, step 8400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 425, step 8500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 430, step 8600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 435, step 8700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 440, step 8800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 445, step 8900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 450, step 9000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 455, step 9100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 460, step 9200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 465, step 9300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 470, step 9400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 475, step 9500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 480, step 9600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 485, step 9700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 490, step 9800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 495, step 9900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 500, step 10000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 505, step 10100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 510, step 10200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 515, step 10300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 520, step 10400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 525, step 10500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 530, step 10600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 535, step 10700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 540, step 10800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 6.0\n",
            "episode 545, step 10900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 550, step 11000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 555, step 11100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 560, step 11200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 565, step 11300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 570, step 11400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 575, step 11500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 580, step 11600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 585, step 11700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 590, step 11800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 595, step 11900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 600, step 12000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 605, step 12100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 610, step 12200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 615, step 12300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 620, step 12400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 625, step 12500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 630, step 12600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 635, step 12700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 640, step 12800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 645, step 12900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 650, step 13000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 655, step 13100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 660, step 13200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 665, step 13300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 670, step 13400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 675, step 13500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 680, step 13600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 685, step 13700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 690, step 13800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 695, step 13900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 700, step 14000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 705, step 14100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 710, step 14200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 715, step 14300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 720, step 14400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 725, step 14500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 730, step 14600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 735, step 14700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 740, step 14800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 745, step 14900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 750, step 15000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 755, step 15100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 760, step 15200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 765, step 15300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 770, step 15400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 775, step 15500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 780, step 15600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 785, step 15700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 790, step 15800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 795, step 15900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 6.0\n",
            "episode 800, step 16000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 805, step 16100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 810, step 16200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 815, step 16300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 820, step 16400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 825, step 16500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 830, step 16600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 835, step 16700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 840, step 16800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 845, step 16900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 850, step 17000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 855, step 17100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 860, step 17200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 865, step 17300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 870, step 17400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 875, step 17500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 880, step 17600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 885, step 17700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 890, step 17800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 895, step 17900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 900, step 18000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 905, step 18100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 910, step 18200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 915, step 18300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 920, step 18400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 925, step 18500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 930, step 18600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 935, step 18700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 940, step 18800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 945, step 18900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 950, step 19000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 955, step 19100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 960, step 19200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 965, step 19300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 970, step 19400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 975, step 19500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 980, step 19600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 985, step 19700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 990, step 19800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 995, step 19900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1000, step 20000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1005, step 20100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1010, step 20200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1015, step 20300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1020, step 20400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1025, step 20500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1030, step 20600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1035, step 20700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1040, step 20800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1045, step 20900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1050, step 21000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1055, step 21100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1060, step 21200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1065, step 21300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1070, step 21400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1075, step 21500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 1080, step 21600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 1085, step 21700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1090, step 21800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1095, step 21900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1100, step 22000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1105, step 22100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1110, step 22200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1115, step 22300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1120, step 22400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1125, step 22500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1130, step 22600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1135, step 22700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1140, step 22800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1145, step 22900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1150, step 23000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1155, step 23100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1160, step 23200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1165, step 23300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1170, step 23400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1175, step 23500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1180, step 23600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1185, step 23700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1190, step 23800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1195, step 23900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1200, step 24000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1205, step 24100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1210, step 24200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1215, step 24300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1220, step 24400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1225, step 24500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1230, step 24600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1235, step 24700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1240, step 24800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1245, step 24900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1250, step 25000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1255, step 25100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1260, step 25200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1265, step 25300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1270, step 25400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1275, step 25500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1280, step 25600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1285, step 25700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1290, step 25800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1295, step 25900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1300, step 26000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1305, step 26100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1310, step 26200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1315, step 26300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1320, step 26400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1325, step 26500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1330, step 26600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1335, step 26700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1340, step 26800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1345, step 26900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1350, step 27000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1355, step 27100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1360, step 27200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1365, step 27300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1370, step 27400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1375, step 27500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1380, step 27600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1385, step 27700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1390, step 27800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1395, step 27900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1400, step 28000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1405, step 28100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1410, step 28200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1415, step 28300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1420, step 28400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1425, step 28500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1430, step 28600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1435, step 28700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1440, step 28800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1445, step 28900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1450, step 29000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1455, step 29100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1460, step 29200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1465, step 29300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1470, step 29400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1475, step 29500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1480, step 29600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1485, step 29700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1490, step 29800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1495, step 29900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1500, step 30000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1505, step 30100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1510, step 30200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1515, step 30300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1520, step 30400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1525, step 30500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1530, step 30600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1535, step 30700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1540, step 30800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1545, step 30900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1550, step 31000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1555, step 31100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1560, step 31200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1565, step 31300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1570, step 31400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1575, step 31500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1580, step 31600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1585, step 31700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1590, step 31800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1595, step 31900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1600, step 32000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1605, step 32100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1610, step 32200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1615, step 32300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1620, step 32400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1625, step 32500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1630, step 32600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1635, step 32700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1640, step 32800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1645, step 32900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1650, step 33000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1655, step 33100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1660, step 33200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1665, step 33300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1670, step 33400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1675, step 33500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1680, step 33600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1685, step 33700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1690, step 33800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1695, step 33900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1700, step 34000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1705, step 34100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1710, step 34200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1715, step 34300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1720, step 34400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1725, step 34500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1730, step 34600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1735, step 34700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 1740, step 34800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1745, step 34900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1750, step 35000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1755, step 35100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1760, step 35200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1765, step 35300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1770, step 35400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1775, step 35500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1780, step 35600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1785, step 35700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1790, step 35800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1795, step 35900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1800, step 36000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1805, step 36100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1810, step 36200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1815, step 36300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1820, step 36400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1825, step 36500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1830, step 36600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1835, step 36700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1840, step 36800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1845, step 36900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1850, step 37000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1855, step 37100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 6.0\n",
            "episode 1860, step 37200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1865, step 37300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1870, step 37400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1875, step 37500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1880, step 37600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1885, step 37700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1890, step 37800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1895, step 37900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1900, step 38000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 6.0\n",
            "episode 1905, step 38100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1910, step 38200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1915, step 38300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1920, step 38400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1925, step 38500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1930, step 38600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1935, step 38700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1940, step 38800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1945, step 38900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1950, step 39000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1955, step 39100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 1960, step 39200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1965, step 39300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 4.0\n",
            "episode 1970, step 39400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1975, step 39500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 1980, step 39600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1985, step 39700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 1990, step 39800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 1995, step 39900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2000, step 40000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2005, step 40100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2010, step 40200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2015, step 40300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2020, step 40400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2025, step 40500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2030, step 40600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2035, step 40700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2040, step 40800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2045, step 40900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2050, step 41000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2055, step 41100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2060, step 41200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2065, step 41300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2070, step 41400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2075, step 41500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2080, step 41600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2085, step 41700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2090, step 41800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2095, step 41900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2100, step 42000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2105, step 42100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2110, step 42200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2115, step 42300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2120, step 42400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2125, step 42500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2130, step 42600, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2135, step 42700, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2140, step 42800, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n",
            "episode 2145, step 42900, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 0.0\n",
            "episode 2150, step 43000, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2155, step 43100, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2160, step 43200, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 2.0\n",
            "episode 2165, step 43300, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 1.0\n",
            "episode 2170, step 43400, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 3.0\n",
            "episode 2175, step 43500, agent=PearlAgent with DeepQLearning, FIFOOffPolicyReplayBuffer, env=<pearl.tutorials.single_item_recommender_system_example.env.RecEnv object at 0x000002BB76C40820>\n",
            "return: 5.0\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 21\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# DQN-vanilla\u001b[39;00m\n\u001b[0;32m      9\u001b[0m agent \u001b[38;5;241m=\u001b[39m PearlAgent(\n\u001b[0;32m     10\u001b[0m     policy_learner\u001b[38;5;241m=\u001b[39mDeepQLearning(\n\u001b[0;32m     11\u001b[0m         state_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     device_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43monline_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumber_of_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_every_x_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn_after_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDQN-return.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(record_period \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m])), info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDQN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\utils\\functional_utils\\train_and_eval\\online_learning.py:107\u001b[0m, in \u001b[0;36monline_learning\u001b[1;34m(agent, env, number_of_episodes, number_of_steps, learn_after_episode, print_every_x_episodes, print_every_x_steps, seed, record_period)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    106\u001b[0m old_total_steps \u001b[38;5;241m=\u001b[39m total_steps\n\u001b[1;32m--> 107\u001b[0m episode_info, episode_total_steps \u001b[38;5;241m=\u001b[39m \u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexploit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearn_after_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearn_after_episode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold_total_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number_of_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m episode_total_steps \u001b[38;5;241m>\u001b[39m record_period:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn episode is longer than the report_period: episode length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode_total_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, record_period \u001b[39m\u001b[38;5;132;01m{record_period}\u001b[39;00m\u001b[38;5;124m. Try using a smaller record_period.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m     )\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\utils\\functional_utils\\train_and_eval\\online_learning.py:275\u001b[0m, in \u001b[0;36mrun_episode\u001b[1;34m(agent, env, learn, exploit, learn_after_episode, total_steps, seed)\u001b[0m\n\u001b[0;32m    272\u001b[0m     episode_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m learn \u001b[38;5;129;01mand\u001b[39;00m learn_after_episode:\n\u001b[1;32m--> 275\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m: cum_reward}\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_risky_sa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\pearl_agent.py:206\u001b[0m, in \u001b[0;36mPearlAgent.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 206\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msafety_module\u001b[38;5;241m.\u001b[39mlearn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_learner)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_learner\u001b[38;5;241m.\u001b[39mon_policy:\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\policy_learners\\policy_learner.py:171\u001b[0m, in \u001b[0;36mPolicyLearner.learn\u001b[1;34m(self, replay_buffer)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, TransitionBatch):\n\u001b[0;32m    170\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 171\u001b[0m     single_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m single_report\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m report:\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\policy_learners\\sequential_decision_making\\deep_td_learning.py:194\u001b[0m, in \u001b[0;36mDeepTDLearning.learn_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m reward_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m batch_size\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m done_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m batch_size\n\u001b[1;32m--> 194\u001b[0m state_action_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_q_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurr_available_actions_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurr_available_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# for duelling, this takes care of the mean subtraction for advantage estimation\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Compute the Bellman Target\u001b[39;00m\n\u001b[0;32m    201\u001b[0m expected_state_action_values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_state_values(batch, batch_size)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discount_factor\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m done_batch\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m    205\u001b[0m ) \u001b[38;5;241m+\u001b[39m reward_batch  \u001b[38;5;66;03m# (batch_size), r + gamma * V(s)\u001b[39;00m\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\neural_networks\\sequential_decision_making\\q_value_networks.py:153\u001b[0m, in \u001b[0;36mVanillaQValueNetwork.get_q_values\u001b[1;34m(self, state_batch, action_batch, curr_available_actions_batch)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_q_values\u001b[39m(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    148\u001b[0m     state_batch: Tensor,\n\u001b[0;32m    149\u001b[0m     action_batch: Tensor,\n\u001b[0;32m    150\u001b[0m     curr_available_actions_batch: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    152\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([state_batch, action_batch], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mD:\\Git-projects\\Pearl\\pearl\\neural_networks\\sequential_decision_making\\q_value_networks.py:144\u001b[0m, in \u001b[0;36mVanillaQValueNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Avatar\\scoop\\apps\\anaconda3-2022.05\\current\\envs\\pearl\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# create a pearl agent\n",
        "\n",
        "action_representation_module = IdentityActionRepresentationModule(\n",
        "    max_number_actions=action_space.n,\n",
        "    representation_dim=action_space.action_dim,\n",
        ")\n",
        "\n",
        "# DQN-vanilla\n",
        "agent = PearlAgent(\n",
        "    policy_learner=DeepQLearning(\n",
        "        state_dim=1,\n",
        "        action_space=action_space,\n",
        "        hidden_dims=[64, 64],\n",
        "        training_rounds=50,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
        "    device_id=-1,\n",
        ")\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=100,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"DQN-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DQN Agent with LSTM history summarization module\n",
        "\n",
        "Now the DQN agent can handle partially observable environments with history summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDauzO74nS4c"
      },
      "outputs": [],
      "source": [
        "# Add a LSTM history summarization module\n",
        "\n",
        "agent = PearlAgent(\n",
        "    policy_learner=DeepQLearning(\n",
        "        state_dim=128,\n",
        "        action_space=action_space,\n",
        "        hidden_dims=[64, 64],\n",
        "        training_rounds=50,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    history_summarization_module=LSTMHistorySummarizationModule(\n",
        "        observation_dim=1,\n",
        "        action_dim=100,\n",
        "        hidden_dim=128,\n",
        "        history_length=8,\n",
        "    ),\n",
        "    replay_buffer=FIFOOffPolicyReplayBuffer(100_000),\n",
        "    device_id=-1,\n",
        ")\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=100,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"DQN-LSTM-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"DQN-LSTM\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bootstrapped DQN Agent with LSTM History Summarization\n",
        "\n",
        "Leveraging the deep exploration value-based algorithm, now the agent can achieve a better performance in a much faster way while being able to still leverage history summarization capability. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7Cpzoi3nVAw"
      },
      "outputs": [],
      "source": [
        "# Better exploration with BootstrappedDQN-LSTM\n",
        "\n",
        "agent = PearlAgent(\n",
        "    policy_learner=BootstrappedDQN(\n",
        "        q_ensemble_network=EnsembleQValueNetwork(\n",
        "            state_dim=128,\n",
        "            action_dim=100,\n",
        "            ensemble_size=10,\n",
        "            output_dim=1,\n",
        "            hidden_dims=[64, 64],\n",
        "            prior_scale=0.3,\n",
        "        ),\n",
        "        action_space=action_space,\n",
        "        training_rounds=50,\n",
        "        action_representation_module=action_representation_module,\n",
        "    ),\n",
        "    history_summarization_module=LSTMHistorySummarizationModule(\n",
        "        observation_dim=1,\n",
        "        action_dim=100,\n",
        "        hidden_dim=128,\n",
        "        history_length=8,\n",
        "    ),\n",
        "    replay_buffer=BootstrapReplayBuffer(100_000, 1.0, 10),\n",
        "    device_id=-1,\n",
        ")\n",
        "\n",
        "info = online_learning(\n",
        "    agent=agent,\n",
        "    env=env,\n",
        "    number_of_steps=number_of_steps,\n",
        "    print_every_x_steps=100,\n",
        "    record_period=record_period,\n",
        "    learn_after_episode=True,\n",
        ")\n",
        "torch.save(info[\"return\"], \"BootstrappedDQN-LSTM-return.pt\")\n",
        "plt.plot(record_period * np.arange(len(info[\"return\"])), info[\"return\"], label=\"BootstrappedDQN-LSTM\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "In this example, we illustrated Pearl's capability of dealing with dynamic action space, standard policy learning, history summarization and intelligent exploration, all in a single agent. By running the code above, you should be able to get agent performance results similar to the figure shown in pearl/tutorials/single_item_recommender_system_example/dqn+lstm+deep_explore.png.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "custom": {
      "cells": [],
      "metadata": {
        "custom": {
          "cells": [],
          "metadata": {
            "custom": {
              "cells": [],
              "metadata": {
                "accelerator": "GPU",
                "colab": {
                  "gpuType": "T4",
                  "include_colab_link": true,
                  "provenance": []
                },
                "fileHeader": "",
                "fileUid": "4316417e-7688-45f2-a94f-24148bfc425e",
                "isAdHoc": false,
                "kernelspec": {
                  "display_name": "pearl (local)",
                  "language": "python",
                  "name": "pearl_local"
                },
                "language_info": {
                  "name": "python"
                }
              },
              "nbformat": 4,
              "nbformat_minor": 2
            },
            "fileHeader": "",
            "fileUid": "1158a851-91bb-437e-a391-aba92448f600",
            "indentAmount": 2,
            "isAdHoc": false,
            "language_info": {
              "name": "plaintext"
            }
          },
          "nbformat": 4,
          "nbformat_minor": 2
        },
        "fileHeader": "",
        "fileUid": "ddf9fa29-09d7-404d-bc1b-62a580952524",
        "indentAmount": 2,
        "isAdHoc": false,
        "language_info": {
          "name": "plaintext"
        }
      },
      "nbformat": 4,
      "nbformat_minor": 2
    },
    "indentAmount": 2,
    "kernelspec": {
      "display_name": "pearl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
